{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64a42a09"
      },
      "source": [
        "# Video Classifier Using CNN and RNN\n",
        "#!dir\n",
        "\n"
      ],
      "id": "64a42a09"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "5g6PDxJ4PyR1",
        "outputId": "c0bfb3c1-6ca2-4204-ee9f-ae4631713750"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "5g6PDxJ4PyR1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports Libraries and Loading Dataset\n",
        "\n",
        "For training our data for classification, the data (Videos) are divided into two folders ( Clear and KnockDown) and split them 80 % for training and 20% for testing"
      ],
      "metadata": {
        "id": "m2ineHdXkFgL"
      },
      "id": "m2ineHdXkFgL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59b4b70e",
        "outputId": "1f23fec7-5106-48ea-80b3-1ff863f005ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Clear', 'KnockDown']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "dataset_path = os.listdir('/content/drive/MyDrive/AI R&D Project/Equestrian/dataset_temp3/train')\n",
        "\n",
        "label_types = os.listdir('/content/drive/MyDrive/AI R&D Project/Equestrian/dataset_temp3/train')\n",
        "print (label_types)"
      ],
      "id": "59b4b70e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "935f06c4"
      },
      "source": [
        "# Preparing Training Data"
      ],
      "id": "935f06c4"
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "# rooms = []\n",
        "# clear_counter=0\n",
        "\n",
        "# for item in dataset_path:\n",
        "#  # Get all the file names\n",
        "\n",
        "#  all_rooms = os.listdir('/content/drive/MyDrive/AI R&D Project/Equestrian/dataset_temp3/train' + '/' +item)\n",
        "\n",
        "#   # Add them to the list\n",
        "#  for room in all_rooms:\n",
        "#     if item=='Clear':\n",
        "#       clear_counter+=1\n",
        "#       if clear_counter==219 :\n",
        "#         break\n",
        "#       else:\n",
        "#         rooms.append((item, str('/content/drive/MyDrive/AI R&D Project/Equestrian/dataset_temp3/train' + '/' +item) + '/' + room))\n",
        "#     else:\n",
        "#       rooms.append((item, str('/content/drive/MyDrive/AI R&D Project/Equestrian/dataset_temp3/train' + '/' +item) + '/' + room))\n",
        "\n",
        "# # Build a dataframe\n",
        "# train_df = pd.DataFrame(data=rooms, columns=['tag', 'video_name'])\n",
        "# print(train_df.head())\n",
        "# print(train_df.tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYaIwjc-M03P",
        "outputId": "6b44da79-84a0-4d11-a54a-cb2cd43d45b1"
      },
      "id": "MYaIwjc-M03P",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         tag                                         video_name\n",
            "0  KnockDown  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "1  KnockDown  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "2  KnockDown  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "3  KnockDown  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "4  KnockDown  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "       tag                                         video_name\n",
            "431  Clear  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "432  Clear  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "433  Clear  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "434  Clear  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "435  Clear  /content/drive/MyDrive/AI R&D Project/Equestri...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tag_counts = train_df['tag'].value_counts()\n",
        "# print(tag_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxkqaDjpTh6X",
        "outputId": "2b47729a-71c0-48f5-8bbe-8135d7ac93ec"
      },
      "id": "SxkqaDjpTh6X",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clear        218\n",
            "KnockDown    218\n",
            "Name: tag, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a list of training Data which is including of each video_name and its label as tag, then build a dataframe as csv file named train.csv"
      ],
      "metadata": {
        "id": "7926vW42lB56"
      },
      "id": "7926vW42lB56"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7e00542",
        "outputId": "7f255719-eeac-4f97-9718-b684fab80d5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     tag                                         video_name\n",
            "0  Clear  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "1  Clear  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "2  Clear  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "3  Clear  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "4  Clear  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "            tag                                         video_name\n",
            "3611  KnockDown  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "3612  KnockDown  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "3613  KnockDown  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "3614  KnockDown  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "3615  KnockDown  /content/drive/MyDrive/AI R&D Project/Equestri...\n"
          ]
        }
      ],
      "source": [
        "rooms = []\n",
        "\n",
        "for item in dataset_path:\n",
        " # Get all the file names\n",
        " all_rooms = os.listdir('/content/drive/MyDrive/AI R&D Project/Equestrian/dataset_temp3/train' + '/' +item)\n",
        "\n",
        " # Add them to the list\n",
        " for room in all_rooms:\n",
        "    rooms.append((item, str('/content/drive/MyDrive/AI R&D Project/Equestrian/dataset_temp3/train' + '/' +item) + '/' + room))\n",
        "\n",
        "# Build a dataframe\n",
        "train_df = pd.DataFrame(data=rooms, columns=['tag', 'video_name'])\n",
        "print(train_df.head())\n",
        "print(train_df.tail())\n"
      ],
      "id": "d7e00542"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27ac79ad"
      },
      "outputs": [],
      "source": [
        "df = train_df.loc[:,['video_name','tag']]\n",
        "df\n",
        "df.to_csv('/content/drive/MyDrive/AI R&D Project/Equestrian/train.csv')"
      ],
      "id": "27ac79ad"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee0897c2"
      },
      "source": [
        "# Preparing Test Data\n",
        "Create a list of testing Data which is including of each video_name and its label as tag, then build a dataframe as csv file named test.csv"
      ],
      "id": "ee0897c2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "413b31f2",
        "outputId": "cb3ccff6-8186-4dee-d1fc-d27a9dc2defb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['KnockDown', 'Clear']\n",
            "Types of activities found:  2\n",
            "         tag                                         video_name\n",
            "0  KnockDown  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "1  KnockDown  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "2  KnockDown  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "3  KnockDown  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "4  KnockDown  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "       tag                                         video_name\n",
            "899  Clear  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "900  Clear  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "901  Clear  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "902  Clear  /content/drive/MyDrive/AI R&D Project/Equestri...\n",
            "903  Clear  /content/drive/MyDrive/AI R&D Project/Equestri...\n"
          ]
        }
      ],
      "source": [
        "dataset_path = os.listdir('/content/drive/MyDrive/AI R&D Project/Equestrian/dataset_temp3/test')\n",
        "print(dataset_path)\n",
        "\n",
        "room_types = os.listdir('/content/drive/MyDrive/AI R&D Project/Equestrian/dataset_temp3/test')\n",
        "print(\"Types of activities found: \", len(dataset_path))\n",
        "\n",
        "rooms = []\n",
        "\n",
        "for item in dataset_path:\n",
        " # Get all the file names\n",
        " all_rooms = os.listdir('/content/drive/MyDrive/AI R&D Project/Equestrian/dataset_temp3/test' + '/' +item)\n",
        "\n",
        " # Add them to the list\n",
        " for room in all_rooms:\n",
        "    rooms.append((item, str('/content/drive/MyDrive/AI R&D Project/Equestrian/dataset_temp3/test' + '/' +item) + '/' + room))\n",
        "\n",
        "# Build a dataframe\n",
        "test_df = pd.DataFrame(data=rooms, columns=['tag', 'video_name'])\n",
        "print(test_df.head())\n",
        "print(test_df.tail())\n",
        "\n",
        "df = test_df.loc[:,['video_name','tag']]\n",
        "df\n",
        "df.to_csv('/content/drive/MyDrive/AI R&D Project/Equestrian/test.csv')"
      ],
      "id": "413b31f2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Tensorflow libraries from its git"
      ],
      "metadata": {
        "id": "f8Jb4XAemoqZ"
      },
      "id": "f8Jb4XAemoqZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c45fb7c1",
        "outputId": "1f8356ab-191e-45ac-e461-44ef058009aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-onqv722x\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-onqv722x\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 73, in resolve\n",
            "    collected = self.factory.collect_root_requirements(root_reqs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 491, in collect_root_requirements\n",
            "    req = self._make_requirement_from_install_req(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 453, in _make_requirement_from_install_req\n",
            "    cand = self._make_candidate_from_link(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 206, in _make_candidate_from_link\n",
            "    self._link_candidate_cache[link] = LinkCandidate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 293, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 156, in __init__\n",
            "    self.dist = self._prepare()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 225, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 304, in _prepare_distribution\n",
            "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 516, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 587, in _prepare_linked_requirement\n",
            "    local_file = unpack_url(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 155, in unpack_url\n",
            "    unpack_vcs_link(link, location, verbosity=verbosity)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 78, in unpack_vcs_link\n",
            "    vcs_backend.unpack(location, url=hide_url(link.url), verbosity=verbosity)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/vcs/versioncontrol.py\", line 608, in unpack\n",
            "    self.obtain(location, url=url, verbosity=verbosity)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/vcs/versioncontrol.py\", line 521, in obtain\n",
            "    self.fetch_new(dest, url, rev_options, verbosity=verbosity)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/vcs/git.py\", line 276, in fetch_new\n",
            "    self.run_command(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/vcs/versioncontrol.py\", line 650, in run_command\n",
            "    return call_subprocess(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/subprocess.py\", line 166, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
            "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 1671, in print\n",
            "    with self:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 864, in __exit__\n",
            "    self._exit_buffer()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 822, in _exit_buffer\n",
            "    self._check_buffer()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 2058, in _check_buffer\n",
            "    text = self._render_buffer(self._buffer[:])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 2079, in _render_buffer\n",
            "    append(\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/tensorflow/docs"
      ],
      "id": "c45fb7c1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "918d9338"
      },
      "outputs": [],
      "source": [
        "from tensorflow_docs.vis import embed\n",
        "from tensorflow import keras\n",
        "from imutils import paths\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "import os"
      ],
      "id": "918d9338"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensorflow Configuration to use 5GB  of GPU memory. It's a useful for managing GPU resources effectively."
      ],
      "metadata": {
        "id": "-K-VapxDnCup"
      },
      "id": "-K-VapxDnCup"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4fed40c"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    tf.config.experimental.set_virtual_device_configuration(\n",
        "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
        "  except RuntimeError as e:\n",
        "    print(e)"
      ],
      "id": "f4fed40c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bdf44bb"
      },
      "source": [
        "Read CSV files containing training and testing data into pandas DataFrames and provides basic information about the size of the datasets. Show a sample of dataframe"
      ],
      "id": "2bdf44bb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "8b716cfb",
        "outputId": "4407bef9-644e-48f0-e724-26b41c3ee3f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total videos for training: 3616\n",
            "Total videos for testing: 904\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0                                         video_name        tag\n",
              "1683        1683  /content/drive/MyDrive/AI R&D Project/Equestri...      Clear\n",
              "453          453  /content/drive/MyDrive/AI R&D Project/Equestri...      Clear\n",
              "656          656  /content/drive/MyDrive/AI R&D Project/Equestri...      Clear\n",
              "3005        3005  /content/drive/MyDrive/AI R&D Project/Equestri...      Clear\n",
              "1959        1959  /content/drive/MyDrive/AI R&D Project/Equestri...      Clear\n",
              "3599        3599  /content/drive/MyDrive/AI R&D Project/Equestri...  KnockDown\n",
              "2788        2788  /content/drive/MyDrive/AI R&D Project/Equestri...      Clear\n",
              "1484        1484  /content/drive/MyDrive/AI R&D Project/Equestri...      Clear\n",
              "149          149  /content/drive/MyDrive/AI R&D Project/Equestri...      Clear\n",
              "1947        1947  /content/drive/MyDrive/AI R&D Project/Equestri...      Clear"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e61cfb68-7443-4210-909e-170bd68e8c82\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>video_name</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1683</th>\n",
              "      <td>1683</td>\n",
              "      <td>/content/drive/MyDrive/AI R&amp;D Project/Equestri...</td>\n",
              "      <td>Clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>453</th>\n",
              "      <td>453</td>\n",
              "      <td>/content/drive/MyDrive/AI R&amp;D Project/Equestri...</td>\n",
              "      <td>Clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>656</th>\n",
              "      <td>656</td>\n",
              "      <td>/content/drive/MyDrive/AI R&amp;D Project/Equestri...</td>\n",
              "      <td>Clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3005</th>\n",
              "      <td>3005</td>\n",
              "      <td>/content/drive/MyDrive/AI R&amp;D Project/Equestri...</td>\n",
              "      <td>Clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1959</th>\n",
              "      <td>1959</td>\n",
              "      <td>/content/drive/MyDrive/AI R&amp;D Project/Equestri...</td>\n",
              "      <td>Clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3599</th>\n",
              "      <td>3599</td>\n",
              "      <td>/content/drive/MyDrive/AI R&amp;D Project/Equestri...</td>\n",
              "      <td>KnockDown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2788</th>\n",
              "      <td>2788</td>\n",
              "      <td>/content/drive/MyDrive/AI R&amp;D Project/Equestri...</td>\n",
              "      <td>Clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1484</th>\n",
              "      <td>1484</td>\n",
              "      <td>/content/drive/MyDrive/AI R&amp;D Project/Equestri...</td>\n",
              "      <td>Clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>149</td>\n",
              "      <td>/content/drive/MyDrive/AI R&amp;D Project/Equestri...</td>\n",
              "      <td>Clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1947</th>\n",
              "      <td>1947</td>\n",
              "      <td>/content/drive/MyDrive/AI R&amp;D Project/Equestri...</td>\n",
              "      <td>Clear</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e61cfb68-7443-4210-909e-170bd68e8c82')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e61cfb68-7443-4210-909e-170bd68e8c82 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e61cfb68-7443-4210-909e-170bd68e8c82');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5a6ab374-d694-4087-98ef-1dbac3999388\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5a6ab374-d694-4087-98ef-1dbac3999388')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5a6ab374-d694-4087-98ef-1dbac3999388 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1138,\n        \"min\": 149,\n        \"max\": 3599,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          149,\n          453,\n          3599\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"/content/drive/MyDrive/AI R&D Project/Equestrian/dataset_temp3/train/Clear/Tim Gredley - Commissaire S - Opglabbeek - 1.55m - August 14. 2022.mp4_0-1750_Clear_19.mp4\",\n          \"/content/drive/MyDrive/AI R&D Project/Equestrian/dataset_temp3/train/Clear/Tim Gredley - Tres Bien Z  - Lanaken - 1.30m - 02.04.2022.mp4_44433-46183_Clear_12.mp4\",\n          \"/content/drive/MyDrive/AI R&D Project/Equestrian/dataset_temp3/train/KnockDown/Tim Gredley - Gentlemen vh Veldhof - Lanaken - 1.45m - 10.04.2022.mp4_53433-55183_Knock Down_15.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tag\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"KnockDown\",\n          \"Clear\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/AI R&D Project/Equestrian/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/AI R&D Project/Equestrian/test.csv\")\n",
        "\n",
        "print(f\"Total videos for training: {len(train_df)}\")\n",
        "print(f\"Total videos for testing: {len(test_df)}\")\n",
        "\n",
        "\n",
        "train_df.sample(10)"
      ],
      "id": "8b716cfb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b93c182a"
      },
      "source": [
        "# Feed the videos through a network:\n"
      ],
      "id": "b93c182a"
    },
    {
      "cell_type": "markdown",
      "source": [
        " preprocess video data, including center cropping, resizing, and channel reordering, making them suitable for consumption by the models, particularly those dealing with video analysis or action recognition."
      ],
      "metadata": {
        "id": "gFP50_B4swbt"
      },
      "id": "gFP50_B4swbt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcd68b72"
      },
      "outputs": [],
      "source": [
        "# The following two methods are taken from this tutorial:\n",
        "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
        "IMG_SIZE = 224\n",
        "\n",
        "\n",
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
        "\n",
        "\n",
        "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            frames.append(frame)\n",
        "\n",
        "            if len(frames) == max_frames:\n",
        "                break\n",
        "    finally:\n",
        "        cap.release()\n",
        "    return np.array(frames)"
      ],
      "id": "fcd68b72"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c243c6ee"
      },
      "source": [
        "   ### Feature Extraction (CNN)\n",
        "   Feature extractor model based on the InceptionV3 architecture using Keras"
      ],
      "id": "c243c6ee"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "388c0afe"
      },
      "outputs": [],
      "source": [
        "def build_feature_extractor():\n",
        "    feature_extractor = keras.applications.InceptionV3(\n",
        "        weights=\"imagenet\",\n",
        "        include_top=False,\n",
        "        pooling=\"avg\",\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    )\n",
        "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
        "\n",
        "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "    preprocessed = preprocess_input(inputs)\n",
        "\n",
        "    outputs = feature_extractor(preprocessed)\n",
        "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
        "\n",
        "\n",
        "feature_extractor = build_feature_extractor()"
      ],
      "id": "388c0afe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "877ca626"
      },
      "source": [
        "### Label Encoding\n",
        "StringLookup layer encode the class labels as integers. Convert 'Clear' Label to '0' and 'KnockDown' to '1'"
      ],
      "id": "877ca626"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "801339d8",
        "outputId": "6d82ee16-c7e5-4a2a-e1b9-6e6b23ae7191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Clear', 'KnockDown']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       ...,\n",
              "       [1],\n",
              "       [1],\n",
              "       [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "label_processor = keras.layers.StringLookup(num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"]))\n",
        "print(label_processor.get_vocabulary())\n",
        "\n",
        "labels = train_df[\"tag\"].values\n",
        "labels = label_processor(labels[..., None]).numpy()\n",
        "labels"
      ],
      "id": "801339d8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fde4ac85"
      },
      "source": [
        "Finally, we can put all the pieces together to create our data processing utility."
      ],
      "id": "fde4ac85"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18db18a3"
      },
      "outputs": [],
      "source": [
        "#print(train_data[0].shape)\n",
        "#train_data[0]"
      ],
      "id": "18db18a3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameters**"
      ],
      "metadata": {
        "id": "MCwXV5yFto4u"
      },
      "id": "MCwXV5yFto4u"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76216366"
      },
      "outputs": [],
      "source": [
        "#Define hyperparameters\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 30\n",
        "\n",
        "MAX_SEQ_LENGTH = 30\n",
        "NUM_FEATURES = 2048"
      ],
      "id": "76216366"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "11befa62",
        "outputId": "5b84ef58-dcb6-467a-8b9d-2a6de275bf91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-14-3a2e1c7bc922>\", line 45, in <cell line: 45>\n",
            "    train_data, train_labels = prepare_all_videos(train_df, \"train\")\n",
            "  File \"<ipython-input-14-3a2e1c7bc922>\", line 34, in prepare_all_videos\n",
            "    temp_frame_features[i, j, :] = feature_extractor.predict(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2655, in predict\n",
            "    tmp_batch_outputs = self.predict_function(iterator)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 832, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 918, in _call\n",
            "    return self._concrete_variable_creation_fn._call_flat(  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1323, in _call_flat\n",
            "    return self._inference_function.call_preflattened(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
            "    flat_outputs = self.call_flat(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
            "    outputs = self._bound_context.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\", line 1486, in call_function\n",
            "    outputs = execute.execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
            "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 878, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 396, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, strict, {})\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 401, in _joinrealpath\n",
            "    def _joinrealpath(path, rest, strict, seen):\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-3a2e1c7bc922>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_all_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_all_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-3a2e1c7bc922>\u001b[0m in \u001b[0;36mprepare_all_videos\u001b[0;34m(df, root_dir)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 temp_frame_features[i, j, :] = feature_extractor.predict(\n\u001b[0m\u001b[1;32m     35\u001b[0m                     \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2654\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2655\u001b[0;31m                         \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2656\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    917\u001b[0m       )\n\u001b[0;32m--> 918\u001b[0;31m       return self._concrete_variable_creation_fn._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    919\u001b[0m           \u001b[0mfiltered_flat_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "def prepare_all_videos(df, root_dir):\n",
        "    num_samples = len(df)\n",
        "    video_paths = df[\"video_name\"].values.tolist()\n",
        "\n",
        "    ##take all classlabels from train_df column named 'tag' and store in labels\n",
        "    labels = df[\"tag\"].values\n",
        "\n",
        "    #convert classlabels to label encoding\n",
        "    labels = label_processor(labels[..., None]).numpy()\n",
        "\n",
        "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
        "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
        "    # masked with padding or not.\n",
        "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\") # 145,20\n",
        "    frame_features = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\") #145,20,2048\n",
        "\n",
        "    # For each video.\n",
        "    for idx, path in enumerate(video_paths):\n",
        "        # Gather all its frames and add a batch dimension.\n",
        "        frames = load_video(os.path.join(root_dir, path))\n",
        "        frames = frames[None, ...]\n",
        "\n",
        "        # Initialize placeholders to store the masks and features of the current video.\n",
        "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "        temp_frame_features = np.zeros(\n",
        "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
        "        )\n",
        "\n",
        "        # Extract features from the frames of the current video.\n",
        "        for i, batch in enumerate(frames):\n",
        "            video_length = batch.shape[0]\n",
        "            length = min(MAX_SEQ_LENGTH, video_length)\n",
        "            for j in range(length):\n",
        "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
        "                    batch[None, j, :]\n",
        "                )\n",
        "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
        "\n",
        "        frame_features[idx,] = temp_frame_features.squeeze()\n",
        "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
        "\n",
        "    return (frame_features, frame_masks), labels\n",
        "\n",
        "\n",
        "train_data, train_labels = prepare_all_videos(train_df, \"train\")\n",
        "test_data, test_labels = prepare_all_videos(test_df, \"test\")\n",
        "\n",
        "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
        "print(f\"Frame masks in train set: {train_data[1].shape}\")\n",
        "\n",
        "\n",
        "\n",
        "print(f\"train_labels in train set: {train_labels.shape}\")\n",
        "\n",
        "print(f\"test_labels in train set: {test_labels.shape}\")\n",
        "\n",
        "# MAX_SEQ_LENGTH = 20, NUM_FEATURES = 2048. We have defined this above under hyper parameters\n",
        "\n",
        "##### Save Data\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "def save_data(data, labels, filename_prefix):\n",
        "    np.save(f\"/content/drive/MyDrive/AI R&D Project/Equestrian/{filename_prefix}_data.npy\", data)\n",
        "    np.save(f\"/content/drive/MyDrive/AI R&D Project/Equestrian/{filename_prefix}_labels.npy\", labels)\n",
        "\n",
        "# Save train and test data\n",
        "save_data(train_data[0], train_labels, \"train\")\n",
        "save_data(test_data[0], test_labels, \"test\")\n",
        "\n",
        "# Save train and test masks\n",
        "np.save(\"/content/drive/MyDrive/AI R&D Project/Equestrian/train_masks.npy\", train_data[1])\n",
        "np.save(\"/content/drive/MyDrive/AI R&D Project/Equestrian/test_masks.npy\", test_data[1])\n",
        "\n",
        "print(\"Data saved successfully.\")\n"
      ],
      "id": "11befa62"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODjLiOFZLvis"
      },
      "source": [
        "Save Data"
      ],
      "id": "ODjLiOFZLvis"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9eklRefK7gV",
        "outputId": "5b5ae8b0-90ed-4276-d9b5-994e9730c8ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved successfully.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "def save_data(data, labels, filename_prefix):\n",
        "    np.save(f\"/content/drive/MyDrive/AI R&D Project/Equestrian/{filename_prefix}_data.npy\", data)\n",
        "    np.save(f\"/content/drive/MyDrive/AI R&D Project/Equestrian/{filename_prefix}_labels.npy\", labels)\n",
        "\n",
        "# Save train and test data\n",
        "save_data(train_data[0], train_labels, \"train\")\n",
        "save_data(test_data[0], test_labels, \"test\")\n",
        "\n",
        "# Save train and test masks\n",
        "np.save(\"/content/drive/MyDrive/AI R&D Project/Equestrian/train_masks.npy\", train_data[1])\n",
        "np.save(\"/content/drive/MyDrive/AI R&D Project/Equestrian/test_masks.npy\", test_data[1])\n",
        "\n",
        "print(\"Data saved successfully.\")\n"
      ],
      "id": "w9eklRefK7gV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72hRsZX7Ly-7"
      },
      "source": [
        "Load Data"
      ],
      "id": "72hRsZX7Ly-7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RylTYcoBLxzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9bf3bb5-889c-4dec-d166-d4177a6ff3bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded train data shape: (3616, 30, 2048)\n",
            "Loaded train labels shape: (3616, 1)\n",
            "Loaded test data shape: (904, 30, 2048)\n",
            "Loaded test labels shape: (904, 1)\n",
            "Loaded train masks shape: (3616, 30)\n",
            "Loaded test masks shape: (904, 30)\n"
          ]
        }
      ],
      "source": [
        "def load_data(filename_prefix):\n",
        "    data = np.load(f\"/content/drive/MyDrive/AI R&D Project/Equestrian/{filename_prefix}_data.npy\")\n",
        "    labels = np.load(f\"/content/drive/MyDrive/AI R&D Project/Equestrian/{filename_prefix}_labels.npy\")\n",
        "    return data, labels\n",
        "\n",
        "# Load train and test data\n",
        "train_data, train_labels = load_data(\"train\")\n",
        "test_data, test_labels = load_data(\"test\")\n",
        "\n",
        "# Load train and test masks\n",
        "train_masks = np.load(\"/content/drive/MyDrive/AI R&D Project/Equestrian/train_masks.npy\")\n",
        "test_masks = np.load(\"/content/drive/MyDrive/AI R&D Project/Equestrian/test_masks.npy\")\n",
        "\n",
        "print(f\"Loaded train data shape: {train_data.shape}\")\n",
        "print(f\"Loaded train labels shape: {train_labels.shape}\")\n",
        "print(f\"Loaded test data shape: {test_data.shape}\")\n",
        "print(f\"Loaded test labels shape: {test_labels.shape}\")\n",
        "print(f\"Loaded train masks shape: {train_masks.shape}\")\n",
        "print(f\"Loaded test masks shape: {test_masks.shape}\")\n"
      ],
      "id": "RylTYcoBLxzL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "407e0827"
      },
      "source": [
        "# The sequence model (RNN)\n",
        "Now, we can feed these extracted features to a sequence model consisting of recurrent layers like GRU."
      ],
      "id": "407e0827"
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels.shape"
      ],
      "metadata": {
        "id": "gwIMMBjtgW2I",
        "outputId": "d7218bec-7f3d-4faa-82d2-3e8b151e3da2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "gwIMMBjtgW2I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3616, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the learning rate scheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# Define the learning rate scheduler callback\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.01)"
      ],
      "metadata": {
        "id": "LqGfAux4RUv5"
      },
      "id": "LqGfAux4RUv5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Model and get the accuracy"
      ],
      "metadata": {
        "id": "06YFLrxRuJ4d"
      },
      "id": "06YFLrxRuJ4d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7382f3c1",
        "outputId": "9235dda0-74c4-4777-e9cc-477f73c19ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "80/80 [==============================] - ETA: 0s - loss: 0.6540 - accuracy: 0.7337\n",
            "Epoch 1: val_loss improved from inf to 0.56449, saving model to ./tmp/video_classifier\n",
            "80/80 [==============================] - 26s 75ms/step - loss: 0.6540 - accuracy: 0.7337 - val_loss: 0.5645 - val_accuracy: 0.8387 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "80/80 [==============================] - ETA: 0s - loss: 0.4176 - accuracy: 0.9660\n",
            "Epoch 2: val_loss improved from 0.56449 to 0.51651, saving model to ./tmp/video_classifier\n",
            "80/80 [==============================] - 2s 25ms/step - loss: 0.4176 - accuracy: 0.9660 - val_loss: 0.5165 - val_accuracy: 0.8387 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "80/80 [==============================] - ETA: 0s - loss: 0.3363 - accuracy: 0.9949\n",
            "Epoch 3: val_loss did not improve from 0.51651\n",
            "80/80 [==============================] - 2s 31ms/step - loss: 0.3363 - accuracy: 0.9949 - val_loss: 0.5293 - val_accuracy: 0.8387 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "79/80 [============================>.] - ETA: 0s - loss: 0.2601 - accuracy: 1.0000\n",
            "Epoch 4: val_loss did not improve from 0.51651\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.2603 - accuracy: 1.0000 - val_loss: 0.5823 - val_accuracy: 0.8387 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "78/80 [============================>.] - ETA: 0s - loss: 0.2144 - accuracy: 1.0000\n",
            "Epoch 5: val_loss did not improve from 0.51651\n",
            "80/80 [==============================] - 3s 34ms/step - loss: 0.2148 - accuracy: 1.0000 - val_loss: 0.6462 - val_accuracy: 0.8387 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "80/80 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 1.0000\n",
            "Epoch 6: val_loss did not improve from 0.51651\n",
            "80/80 [==============================] - 2s 24ms/step - loss: 0.1798 - accuracy: 1.0000 - val_loss: 0.7133 - val_accuracy: 0.8387 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "78/80 [============================>.] - ETA: 0s - loss: 0.1650 - accuracy: 1.0000\n",
            "Epoch 7: val_loss did not improve from 0.51651\n",
            "80/80 [==============================] - 2s 24ms/step - loss: 0.1641 - accuracy: 1.0000 - val_loss: 0.7469 - val_accuracy: 0.8387 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "78/80 [============================>.] - ETA: 0s - loss: 0.1395 - accuracy: 1.0000\n",
            "Epoch 8: val_loss did not improve from 0.51651\n",
            "80/80 [==============================] - 2s 29ms/step - loss: 0.1386 - accuracy: 1.0000 - val_loss: 0.7162 - val_accuracy: 0.8387 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "80/80 [==============================] - ETA: 0s - loss: 0.1203 - accuracy: 1.0000\n",
            "Epoch 9: val_loss did not improve from 0.51651\n",
            "80/80 [==============================] - 3s 37ms/step - loss: 0.1203 - accuracy: 1.0000 - val_loss: 0.7851 - val_accuracy: 0.8387 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "78/80 [============================>.] - ETA: 0s - loss: 0.1069 - accuracy: 1.0000\n",
            "Epoch 10: val_loss did not improve from 0.51651\n",
            "80/80 [==============================] - 2s 27ms/step - loss: 0.1069 - accuracy: 1.0000 - val_loss: 0.7747 - val_accuracy: 0.8387 - lr: 0.0010\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.3639 - accuracy: 0.9524\n",
            "Test accuracy: 95.24%\n"
          ]
        }
      ],
      "source": [
        "# Utility for our sequence model.\n",
        "def get_sequence_model():\n",
        "    class_vocab = label_processor.get_vocabulary()\n",
        "\n",
        "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
        "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "\n",
        "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
        "    # https://keras.io/api/layers/recurrent_layers/gru/\n",
        "    # x = keras.layers.GRU(16, return_sequences=True)(frame_features_input, mask=mask_input)\n",
        "    # x = keras.layers.GRU(8)(x)\n",
        "    # x = keras.layers.Dropout(0.4)(x)\n",
        "    # x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
        "    ###\n",
        "    # Add more GRU layers\n",
        "\n",
        "    x = keras.layers.GRU(16, return_sequences=True)(frame_features_input, mask=mask_input)\n",
        "    x = keras.layers.GRU(16, return_sequences=True)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)  # Add BatchNormalization layer\n",
        "    x = keras.layers.GRU(8)(x)\n",
        "    x = keras.layers.BatchNormalization()(x)  # Add BatchNormalization layer\n",
        "    # Add L2 regularization to the Dense layers\n",
        "    x = keras.layers.Dense(8, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01))(x)\n",
        "    # Experiment with different dropout rates\n",
        "    x = keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "    ####\n",
        "\n",
        "    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n",
        "\n",
        "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
        "\n",
        "    rnn_model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return rnn_model\n",
        "\n",
        "EPOCHS = 10\n",
        "# Utility for running experiments.\n",
        "def run_experiment():\n",
        "    filepath = \"./tmp/video_classifier\"\n",
        "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
        "    )\n",
        "\n",
        "    seq_model = get_sequence_model()\n",
        "    history = seq_model.fit(\n",
        "        [train_data, train_masks],\n",
        "        train_labels,\n",
        "        validation_split=0.3,\n",
        "        epochs=EPOCHS,\n",
        "        # callbacks=[checkpoint],\n",
        "        callbacks=[checkpoint, reduce_lr],\n",
        "    )\n",
        "    #--------------------------------------------\n",
        "    # history = seq_model.fit(\n",
        "    #     [train_data[0], train_data[1]],\n",
        "    #     train_labels,\n",
        "    #     validation_split=0.3,\n",
        "    #     epochs=EPOCHS,\n",
        "    #     callbacks=[checkpoint],\n",
        "    # )\n",
        "\n",
        "    # seq_model.load_weights(filepath)\n",
        "    # _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n",
        "    #-------------------------------------------------\n",
        "\n",
        "    seq_model.load_weights(filepath)\n",
        "    _, accuracy = seq_model.evaluate([test_data, test_masks], test_labels)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history, seq_model\n",
        "\n",
        "\n",
        "history, sequence_model = run_experiment()"
      ],
      "id": "7382f3c1"
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import Input, GRU, Dropout, Dense, Masking\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "def get_sequence_model():\n",
        "    class_vocab = label_processor.get_vocabulary()\n",
        "    MAX_SEQ_LENGTH = 30  # Define your MAX_SEQ_LENGTH\n",
        "    NUM_FEATURES = 2048   # Define your NUM_FEATURES\n",
        "\n",
        "    frame_features_input = Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
        "    mask_input = Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "\n",
        "    x = Masking(mask_value=0.0)(frame_features_input)  # Masking layer to handle variable sequence lengths\n",
        "    x = GRU(64, return_sequences=True)(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = GRU(32)(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(32, activation=\"relu\")(x)\n",
        "    output = Dense(len(class_vocab), activation=\"softmax\")(x)\n",
        "\n",
        "    rnn_model = Model([frame_features_input, mask_input], output)\n",
        "\n",
        "    optimizer = Adam(learning_rate=0.0001)\n",
        "    rnn_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "    return rnn_model\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "def run_experiment():\n",
        "    filepath = \"./tmp/video_classifier\"\n",
        "    checkpoint = ModelCheckpoint(filepath, save_weights_only=True, save_best_only=True, verbose=1)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001)\n",
        "\n",
        "    seq_model = get_sequence_model()\n",
        "    history = seq_model.fit(\n",
        "        [train_data, train_masks],\n",
        "        train_labels,\n",
        "        validation_split=0.3,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=[checkpoint, reduce_lr],\n",
        "        batch_size=64  # Increase batch size for faster convergence\n",
        "    )\n",
        "\n",
        "    seq_model.load_weights(filepath)\n",
        "    _, accuracy = seq_model.evaluate([test_data, test_masks], test_labels)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history, seq_model\n",
        "\n",
        "history, sequence_model = run_experiment()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlVWeDU1XKp7",
        "outputId": "5f291289-386a-478c-c7d5-9e96aa5e06a4"
      },
      "id": "JlVWeDU1XKp7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.3179 - accuracy: 0.9034\n",
            "Epoch 1: val_loss improved from inf to 0.51275, saving model to ./tmp/video_classifier\n",
            "40/40 [==============================] - 13s 135ms/step - loss: 0.3157 - accuracy: 0.9048 - val_loss: 0.5128 - val_accuracy: 0.8387 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.1301 - accuracy: 0.9944\n",
            "Epoch 2: val_loss did not improve from 0.51275\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.1299 - accuracy: 0.9945 - val_loss: 0.6177 - val_accuracy: 0.8387 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0765 - accuracy: 0.9996\n",
            "Epoch 3: val_loss did not improve from 0.51275\n",
            "40/40 [==============================] - 1s 30ms/step - loss: 0.0762 - accuracy: 0.9996 - val_loss: 0.6933 - val_accuracy: 0.8387 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0544 - accuracy: 0.9996\n",
            "Epoch 4: val_loss did not improve from 0.51275\n",
            "40/40 [==============================] - 1s 31ms/step - loss: 0.0544 - accuracy: 0.9996 - val_loss: 0.7578 - val_accuracy: 0.8387 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0386 - accuracy: 1.0000\n",
            "Epoch 5: val_loss did not improve from 0.51275\n",
            "40/40 [==============================] - 1s 29ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.8121 - val_accuracy: 0.8387 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0301 - accuracy: 0.9996\n",
            "Epoch 6: val_loss did not improve from 0.51275\n",
            "40/40 [==============================] - 1s 29ms/step - loss: 0.0300 - accuracy: 0.9996 - val_loss: 0.8616 - val_accuracy: 0.8387 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.0233 - accuracy: 1.0000\n",
            "Epoch 7: val_loss did not improve from 0.51275\n",
            "40/40 [==============================] - 1s 31ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.9044 - val_accuracy: 0.8387 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 8: val_loss did not improve from 0.51275\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.9445 - val_accuracy: 0.8387 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.0153 - accuracy: 1.0000\n",
            "Epoch 9: val_loss did not improve from 0.51275\n",
            "40/40 [==============================] - 1s 29ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.9811 - val_accuracy: 0.8387 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 1.0000\n",
            "Epoch 10: val_loss did not improve from 0.51275\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.0138 - val_accuracy: 0.8387 - lr: 1.0000e-04\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.1931 - accuracy: 0.9524\n",
            "Test accuracy: 95.24%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Loss and Accuracy Graphs"
      ],
      "metadata": {
        "id": "bNMPxeMEuYc3"
      },
      "id": "bNMPxeMEuYc3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "txhVjEBewCyy",
        "outputId": "d18fb769-6591-4d6e-ed0e-f95aae47380e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "id": "txhVjEBewCyy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f1f1681"
      },
      "source": [
        "# Inference\n",
        "\n",
        "Prediction: Predict whether a video is a 'Clear' jump or unclear jump (Knockdown)"
      ],
      "id": "6f1f1681"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "846a5956",
        "outputId": "ad6db1e7-62d4-49f2-e9d9-a31e8d2c4d1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test video path: /content/drive/MyDrive/AI R&D Project/Equestrian/dataset_temp3/test/Clear/Tim Gredley - Medoc de Toxandria - Hickstead - 1.60m - 28.07.2023 Round 1.mp4_32133-33883_Clear_7.mp4\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 138ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 134ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 145ms/step\n",
            "1/1 [==============================] - 0s 148ms/step\n",
            "1/1 [==============================] - 0s 160ms/step\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "1/1 [==============================] - 0s 136ms/step\n",
            "1/1 [==============================] - 0s 135ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 152ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 136ms/step\n",
            "1/1 [==============================] - 0s 140ms/step\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "1/1 [==============================] - 0s 145ms/step\n",
            "1/1 [==============================] - 0s 140ms/step\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "1/1 [==============================] - 0s 157ms/step\n",
            "1/1 [==============================] - 0s 141ms/step\n",
            "1/1 [==============================] - 0s 138ms/step\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "  Clear: 85.00%\n",
            "  KnockDown: 15.00%\n"
          ]
        }
      ],
      "source": [
        "def prepare_single_video(frames):\n",
        "    frames = frames[None, ...]\n",
        "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
        "\n",
        "    for i, batch in enumerate(frames):\n",
        "        video_length = batch.shape[0]\n",
        "        length = min(MAX_SEQ_LENGTH, video_length)\n",
        "        for j in range(length):\n",
        "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
        "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
        "\n",
        "    return frame_features, frame_mask\n",
        "\n",
        "\n",
        "def sequence_prediction(path):\n",
        "    class_vocab = label_processor.get_vocabulary()\n",
        "\n",
        "    frames = load_video(os.path.join(\"test\", path))\n",
        "    frame_features, frame_mask = prepare_single_video(frames)\n",
        "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
        "\n",
        "    for i in np.argsort(probabilities)[::-1]:\n",
        "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
        "    return frames\n",
        "\n",
        "test_video = np.random.choice(test_df[\"video_name\"].values.tolist())\n",
        "print(f\"Test video path: {test_video}\")\n",
        "\n",
        "test_frames = sequence_prediction(test_video)\n"
      ],
      "id": "846a5956"
    },
    {
      "cell_type": "code",
      "source": [
        "t=test_df[test_df['tag'] == 'KnockDown']\n",
        "test_video = np.random.choice(t[\"video_name\"].values.tolist())\n",
        "print(f\"Test video path: {test_video}\")\n",
        "\n",
        "test_frames = sequence_prediction(test_video)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1ifIWl7pM3h",
        "outputId": "089b9fc1-3a1c-4501-9478-f49491a7721a"
      },
      "id": "o1ifIWl7pM3h",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test video path: /content/drive/MyDrive/AI R&D Project/Equestrian/dataset_temp3/test/KnockDown/Tim Gredley - Sparks 55 - St Tropez - 1.45m - 10.09.2022.mp4_44233-45983_Knock Down_12.mp4\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "1/1 [==============================] - 0s 145ms/step\n",
            "1/1 [==============================] - 0s 140ms/step\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "1/1 [==============================] - 0s 140ms/step\n",
            "1/1 [==============================] - 0s 138ms/step\n",
            "1/1 [==============================] - 0s 134ms/step\n",
            "1/1 [==============================] - 0s 150ms/step\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "1/1 [==============================] - 0s 140ms/step\n",
            "1/1 [==============================] - 0s 154ms/step\n",
            "1/1 [==============================] - 0s 134ms/step\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "  Clear: 86.36%\n",
            "  KnockDown: 13.64%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "eDaYv5nc8-LC",
        "outputId": "89220e05-4443-4b9b-8e3a-9b14246d9e6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test video path: /content/drive/MyDrive/AI R&D Project/Equestrian/dataset_temp3/test/Clear/Tim Gredley - Imperial Hbf - Abu Dhabi - 1.50m - 15.01.2023.mp4_73874-75624_Clear_20.mp4\n",
            "1/1 [==============================] - 0s 147ms/step\n",
            "1/1 [==============================] - 0s 161ms/step\n",
            "1/1 [==============================] - 0s 149ms/step\n",
            "1/1 [==============================] - 0s 148ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-17e86a4d746d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test video path: {test_video}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_video\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-490ebea2793f>\u001b[0m in \u001b[0;36msequence_prediction\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mframe_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_single_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-490ebea2793f>\u001b[0m in \u001b[0;36mprepare_single_video\u001b[0;34m(frames)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_SEQ_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mframe_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mframe_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# 1 = not masked, 0 = masked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2653\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2654\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2655\u001b[0;31m                         \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2656\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m                             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    878\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "test_video = np.random.choice(test_df[\"video_name\"].values.tolist())\n",
        "print(f\"Test video path: {test_video}\")\n",
        "\n",
        "test_frames = sequence_prediction(test_video)"
      ],
      "id": "eDaYv5nc8-LC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VwgvbhJq7qg",
        "outputId": "5ed2d5cb-c9d6-42c9-939d-48f131314a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test video path: /content/drive/MyDrive/AI R&D Project/Equestrian/dataset_temp3/test/KnockDown/Tim Gredley - Belinda  - Lanaken - 1.45m - 01.04.2022.mp4_False_13.mp4\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 134ms/step\n",
            "1/1 [==============================] - 0s 141ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 148ms/step\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 148ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 139ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "1/1 [==============================] - 0s 134ms/step\n",
            "1/1 [==============================] - 0s 208ms/step\n",
            "1/1 [==============================] - 0s 234ms/step\n",
            "1/1 [==============================] - 0s 249ms/step\n",
            "1/1 [==============================] - 0s 222ms/step\n",
            "1/1 [==============================] - 0s 223ms/step\n",
            "1/1 [==============================] - 0s 233ms/step\n",
            "1/1 [==============================] - 0s 230ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "  Clear: 89.52%\n",
            "  KnockDown: 10.48%\n"
          ]
        }
      ],
      "source": [
        "test_video = \"/content/drive/MyDrive/AI R&D Project/Equestrian/dataset_temp3/test/KnockDown/Tim Gredley - Belinda  - Lanaken - 1.45m - 01.04.2022.mp4_False_13.mp4\"\n",
        "print(f\"Test video path: {test_video}\")\n",
        "# \"D:\\UNI\\British_equistrian\\Ammar\\Chunks\\Custom\\train\\failure\\Ben Maher - Explosion W - Aachen - 1.60m - 03.07.2022 Round 2_False_10.mp4\"\n",
        "# \"D:\\UNI\\British_equistrian\\Ammar\\Chunks\\Custom\\train\\failure\\Scott Brash - Hello Jefferson - Aachen - 1.60m - 03.07.2022 Round 2_False_0.mp4\"\n",
        "# \"D:\\UNI\\British_equistrian\\Ammar\\Chunks\\Custom\\train\\failure\\Ben Maher - Explosion W - Aachen - 1.60m - 03.07.2022 Round 2.mp4_False_10.mp4\"\n",
        "test_frames = sequence_prediction(test_video)"
      ],
      "id": "8VwgvbhJq7qg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502,
          "resources": {
            "http://localhost:8080/content/drive/MyDrive/AI%20R&D%20Project/Equestrian/dataset/train/failure/Harry%20Charles%20-%20Romeo%2088%20-%20Aachen%20-%201.60m%20-%2003.07.2022%20Round%202_False_4.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "ok": false,
              "status": 404,
              "status_text": ""
            }
          }
        },
        "id": "YwKEPpIEqAe1",
        "outputId": "06aafb44-36e3-44d7-edee-2702682a2e3f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<video width=\"640\" height=\"480\" controls>\n",
              "  <source src=\"/content/drive/MyDrive/AI R&D Project/Equestrian/dataset/train/failure/Harry Charles - Romeo 88 - Aachen - 1.60m - 03.07.2022 Round 2_False_4.mp4\" type=\"video/mp4\">\n",
              "</video>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "# Replace 'video.mp4' with the name of your .mp4 file\n",
        "video_path = 'video.mp4'\n",
        "\n",
        "# Generate HTML code to embed the video\n",
        "html_code = f'''\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=\"{test_video}\" type=\"video/mp4\">\n",
        "</video>\n",
        "'''\n",
        "\n",
        "# Display the HTML code\n",
        "HTML(html_code)\n"
      ],
      "id": "YwKEPpIEqAe1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462,
          "resources": {
            "http://localhost:8080/content/drive/MyDrive/AI%20R&D%20Project/Equestrian/dataset/train/failure/Scott%20Brash%20-%20Hello%20Jefferson%20-%20Aachen%20-%201.60m%20-%2003.07.2022%20Round%202_False_0.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "ok": false,
              "status": 404,
              "status_text": ""
            }
          }
        },
        "id": "6309d87b",
        "outputId": "edb2241a-1355-45cf-b72c-ca740b5adfc7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <video alt=\"train\" width=\"520\" height=\"440\" controls>\n",
              "        <source src=\"/content/drive/MyDrive/AI R&D Project/Equestrian/dataset/train/failure/Scott Brash - Hello Jefferson - Aachen - 1.60m - 03.07.2022 Round 2_False_0.mp4\" type=\"video/mp4\" style=\"height:300px;width:300px\">\n",
              "    </video>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"\n",
        "    <video alt=\"train\" width=\"520\" height=\"440\" controls>\n",
        "        <source src=\"/content/drive/MyDrive/AI R&D Project/Equestrian/dataset/train/failure/Scott Brash - Hello Jefferson - Aachen - 1.60m - 03.07.2022 Round 2_False_0.mp4\" type=\"video/mp4\" style=\"height:300px;width:300px\">\n",
        "    </video>\n",
        "\"\"\")\n"
      ],
      "id": "6309d87b"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}